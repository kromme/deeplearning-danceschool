{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of impersonator_plus_plus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gbhC8six1TH"
      },
      "source": [
        "# Deep Learning Dance School\n",
        "Using Impersonator++.\n",
        "\n",
        "I used the [Impersonator++](https://github.com/iPERDance/iPERCore) repo to map the movements of my GF's dancing video on a static picture of me. The following script was ran on Google Colab.\n",
        "\n",
        "**Note**: Make sure that your runtime type is 'Python 3.6+ with GPU acceleration'. To do so, go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\".\n",
        "\n",
        "## Dependencies\n",
        "### System Requirements\n",
        " - Linux (test on Ubuntu 16.04 and 18.04) or Windows (test on windows 10)\n",
        " - CUDA 10.1, 10.2, or 11.0\n",
        " - gcc 7.5+ (needs to support C++14)\n",
        " - ffmpeg (ffprobe) 4.3.1+\n",
        "\n",
        "### Python Requirements\n",
        "- Python 3.6+\n",
        "- PyTorch tested on 1.7.0\n",
        "- Torchvison tested on 0.8.1\n",
        "- mmcv-full test on 1.2.0\n",
        "- numpy>=1.19.3\n",
        "- scipy>=1.5.2\n",
        "- scikit-image>=0.17.2\n",
        "- opencv-python>=4.4.0.40\n",
        "- tensorboardX>=2.1\n",
        "- tqdm>=4.48.2\n",
        "- visdom>=0.1.8.9\n",
        "- easydict>=1.9\n",
        "- toml>=0.10.2\n",
        "- git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
        "- git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
        "- git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
        "\n",
        "## Guidelines\n",
        "### Source/Photo Guidelines:\n",
        "- Try to capture the source images with the same static background without too complex scene structures. If possible, we recommend using the\n",
        "actual background.\n",
        "- The person in the source images holds an A-pose for introducing the most visible textures.\n",
        "- It is recommended to capture the source images in an environment without too much contrast in lighting conditions and lock auto-exposure and auto-focus of the camera.\n",
        "\n",
        "### Reference/Video Guidelines:\n",
        "- Make sure that there is only **one** person in the reference video. Since,currently, our system does not support multiple people tracking. If there are multiple people, you need firstly use other video processing tools to crop the video.\n",
        "- Make sure that capture the video with full body person. Half body will result in bad results.\n",
        "- Try to capture the video with the static camera lens, and make sure that there is no too much zoom-in, zoom-out, panning, lens swichtings, and camera transitions. If there are multiple lens switchting and camera transitions, you need firstly use other video processing tools to crop the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTh8Pl_w4MK"
      },
      "source": [
        "# 1. Installation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTjLpNgipXPR"
      },
      "source": [
        "## 1.1 Instal ffmpeg (ffprobe) and set CUDA_HOME to the system enviroments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPl00TgplS-",
        "outputId": "acdbaff3-e569-42e0-8a07-74de33a5a417"
      },
      "source": [
        "# Install ffmpeg (ffprobe)\n",
        "!apt-get install ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45P7Uicpsuc",
        "outputId": "09843aac-e788-4604-b6ea-8c650468f090"
      },
      "source": [
        "# set CUDA_HOME, here we use CUDA 10.1\n",
        "import os\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda-10.1\"\n",
        "\n",
        "!echo $CUDA_HOME"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYAJxIf9xBxU"
      },
      "source": [
        "## 1.1 Clone iPERCore Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6oiRq1xKvm",
        "outputId": "d8d674ad-131f-4d18-969b-537853a2c678"
      },
      "source": [
        "!git clone https://github.com/iPERDance/iPERCore.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'iPERCore'...\n",
            "remote: Enumerating objects: 332, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (261/261), done.\u001b[K\n",
            "remote: Total 332 (delta 67), reused 289 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (332/332), 11.65 MiB | 27.48 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9-b45uwx4f"
      },
      "source": [
        "## 1.2 Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aXNebVxv72E",
        "outputId": "0bb7ef7e-6716-4e01-ea93-7a9fe924e6c1"
      },
      "source": [
        "cd /content/iPERCore/"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/iPERCore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZAZlLRHH2lq",
        "outputId": "efba9a53-b7b6-4cbb-d4d1-653eb7fd4fb5"
      },
      "source": [
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3 -m pip install pip==20.2.4\n",
            "Collecting pip==20.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/28/91f26bd088ce8e22169032100d4260614fc3da435025ff389ef1d396a433/pip-20.2.4-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.2.4\n",
            "/usr/bin/python3 -m pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (1.19.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (0.16.0)\n",
            "/usr/bin/python3 -m pip install torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torchvision==0.8.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.1+cu101) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.1+cu101) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.1+cu101) (7.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision==0.8.1+cu101) (3.7.4.3)\n",
            "/usr/bin/python3 -m pip install mmcv-full==1.2.0+torch1.7.0+cu101 -f https://download.openmmlab.com/mmcv/dist/index.html\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/index.html\n",
            "Collecting mmcv-full==1.2.0+torch1.7.0+cu101\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/1.2.0/torch1.7.0/cu101/mmcv_full-1.2.0%2Btorch1.7.0%2Bcu101-cp36-cp36m-manylinux1_x86_64.whl (19.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.8 MB 159 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv-full==1.2.0+torch1.7.0+cu101) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmcv-full==1.2.0+torch1.7.0+cu101) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv-full==1.2.0+torch1.7.0+cu101) (1.19.4)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv-full==1.2.0+torch1.7.0+cu101) (3.13)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.2.0 yapf-0.30.0\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "/usr/bin/python3 -m pip install numpy>=1.19.3\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "/usr/bin/python3 -m pip install scipy>=1.5.2\n",
            "Collecting scipy>=1.5.2\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy>=1.5.2) (1.19.4)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.5.4\n",
            "/usr/bin/python3 -m pip install scikit-image>=0.17.2\n",
            "Collecting scikit-image>=0.17.2\n",
            "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 172 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (1.5.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (2020.9.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.17.2) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.17.2) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.17.2) (1.15.0)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.17.2\n",
            "/usr/bin/python3 -m pip install opencv-python>=4.4.0.40\n",
            "Collecting opencv-python>=4.4.0.40\n",
            "  Downloading opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.5 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.4.0.40) (1.19.4)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.4.0.46\n",
            "/usr/bin/python3 -m pip install tensorboardX>=2.1\n",
            "Collecting tensorboardX>=2.1\n",
            "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=2.1) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=2.1) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=2.1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX>=2.1) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n",
            "/usr/bin/python3 -m pip install tqdm>=4.48.2\n",
            "Collecting tqdm>=4.48.2\n",
            "  Downloading tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.54.1\n",
            "/usr/bin/python3 -m pip install visdom>=0.1.8.9\n",
            "Collecting visdom>=0.1.8.9\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (1.5.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (20.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.28-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 19.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.9) (7.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.9) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.9) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.9) (2.10)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655249 sha256=26847a122a6f3609c07b44f0a49e6ecaf28120cce3df929419b9a93258c6bf6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/cd/fb/005445070865d4e45365b2946ee88085a7392370f152cf371c\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5711 sha256=c7d32690f0ab72027be5e9dcf008b90aa6a78c2ba42418bf952627da7df5579f\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/79/ec/084a3a2e348d72852cc0c13c559c923c13ca54db86e699b681\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n",
            "/usr/bin/python3 -m pip install easydict>=1.9\n",
            "Requirement already satisfied: easydict>=1.9 in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "/usr/bin/python3 -m pip install toml>=0.10.2\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "Collecting git+https://github.com/open-mmlab/mmdetection.git@8179440ec5f75fe95484854af61ce6f6279f3bbc\n",
            "  Cloning https://github.com/open-mmlab/mmdetection.git (to revision 8179440ec5f75fe95484854af61ce6f6279f3bbc) to /tmp/pip-req-build-sdgq0dgz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mmdet==2.6.0) (3.2.2)\n",
            "Collecting mmpycocotools\n",
            "  Downloading mmpycocotools-12.0.3.tar.gz (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmdet==2.6.0) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mmdet==2.6.0) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.6.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.6.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.6.0) (2.4.7)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from mmpycocotools->mmdet==2.6.0) (50.3.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from mmpycocotools->mmdet==2.6.0) (0.29.21)\n",
            "Building wheels for collected packages: mmdet, mmpycocotools, terminaltables\n",
            "  Building wheel for mmdet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmdet: filename=mmdet-2.6.0-py3-none-any.whl size=490162 sha256=ed50da88cf8d0bee7be8b0153dab3f5f91dbabb2faf4f71fa7b974925a4000e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/18/de/3944df77640ab04dedb7ba46b1da7eceb15570c00ba4da7a04\n",
            "  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp36-cp36m-linux_x86_64.whl size=265911 sha256=460f8f6544d7c4e675e10d3a7c33cb81d3f31c76428db81798db6f702bb27be6\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/e9/2f/545d78370691036bb34a3781984de6236882e367c97060b1ac\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=8b5da438ace9edb93ee6b2a395f3526ed7cd51cecd08ede972e160ad403796cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/1b/58/c23af2fe683acd8edc15d5a1268f0242be1ff2cf827fe34737\n",
            "Successfully built mmdet mmpycocotools terminaltables\n",
            "Installing collected packages: mmpycocotools, terminaltables, mmdet\n",
            "Successfully installed mmdet-2.6.0 mmpycocotools-12.0.3 terminaltables-3.1.0\n",
            "/usr/bin/python3 -m pip install git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "Collecting git+https://github.com/open-mmlab/mmediting@d4086aaf8a36ae830f1714aad585900d24ad1156\n",
            "  Cloning https://github.com/open-mmlab/mmediting (to revision d4086aaf8a36ae830f1714aad585900d24ad1156) to /tmp/pip-req-build-tkaz7xqf\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from mmedit==0.5.0) (0.99)\n",
            "Requirement already satisfied: mmcv-full>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from mmedit==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from mmedit==0.5.0) (0.17.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from mmedit==0.5.0) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.6/dist-packages (from mmedit==0.5.0) (0.30.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (3.13)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.6/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (1.19.4)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (4.4.0.46)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmcv-full>=1.0.0->mmedit==0.5.0) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (2.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (2020.9.3)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (1.5.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->mmedit==0.5.0) (1.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (1.7.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (1.17.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->mmedit==0.5.0) (1.32.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mmedit==0.5.0) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->mmedit==0.5.0) (4.4.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->mmedit==0.5.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->mmedit==0.5.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->mmedit==0.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->mmedit==0.5.0) (0.4.8)\n",
            "Building wheels for collected packages: mmedit\n",
            "  Building wheel for mmedit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmedit: filename=mmedit-0.5.0-py2.py3-none-any.whl size=220150 sha256=ae1bfe85f725b15a9c76df0ad052b325e7d9e92616aa6b90aa4da77367db191b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/bf/79/986d5743ff280eccd7b106e99c3342f953c45cc3f5a4be49cf\n",
            "Successfully built mmedit\n",
            "Installing collected packages: mmedit\n",
            "Successfully installed mmedit-0.5.0\n",
            "/usr/bin/python3 -m pip install git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "Collecting git+https://github.com/iPERDance/neural_renderer.git@e5f54f71a8941acf372514eb92e289872f272653\n",
            "  Cloning https://github.com/iPERDance/neural_renderer.git (to revision e5f54f71a8941acf372514eb92e289872f272653) to /tmp/pip-req-build-coixabt_\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (1.19.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (0.8.1+cu101)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (0.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (4.54.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from neural-renderer==1.1.3) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->neural-renderer==1.1.3) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->neural-renderer==1.1.3) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->neural-renderer==1.1.3) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->neural-renderer==1.1.3) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->neural-renderer==1.1.3) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image->neural-renderer==1.1.3) (2020.9.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->neural-renderer==1.1.3) (2.5)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->neural-renderer==1.1.3) (1.5.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->neural-renderer==1.1.3) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->neural-renderer==1.1.3) (1.15.0)\n",
            "Building wheels for collected packages: neural-renderer\n",
            "  Building wheel for neural-renderer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neural-renderer: filename=neural_renderer-1.1.3-cp36-cp36m-linux_x86_64.whl size=5681282 sha256=7c016bfd1725c669538d6573380412fa67f4591f1713675fc540a02b8e44c849\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/e7/3d/5237b02dbbfb608dc8cf5a2925fda0797fe7bc2c677e2812b1\n",
            "Successfully built neural-renderer\n",
            "Installing collected packages: neural-renderer\n",
            "Successfully installed neural-renderer-1.1.3\n",
            "running develop\n",
            "running egg_info\n",
            "creating iPERCore.egg-info\n",
            "writing iPERCore.egg-info/PKG-INFO\n",
            "writing dependency_links to iPERCore.egg-info/dependency_links.txt\n",
            "writing entry points to iPERCore.egg-info/entry_points.txt\n",
            "writing requirements to iPERCore.egg-info/requires.txt\n",
            "writing top-level names to iPERCore.egg-info/top_level.txt\n",
            "writing manifest file 'iPERCore.egg-info/SOURCES.txt'\n",
            "writing manifest file 'iPERCore.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/iPERCore.egg-link (link to .)\n",
            "Adding iPERCore 0.1.1 to easy-install.pth file\n",
            "Installing run_imitator script to /usr/local/bin\n",
            "\n",
            "Installed /content/iPERCore\n",
            "Processing dependencies for iPERCore==0.1.1\n",
            "Searching for toml==0.10.2\n",
            "Best match: toml 0.10.2\n",
            "Adding toml 0.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for easydict==1.9\n",
            "Best match: easydict 1.9\n",
            "Adding easydict 1.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for visdom==0.1.8.9\n",
            "Best match: visdom 0.1.8.9\n",
            "Adding visdom 0.1.8.9 to easy-install.pth file\n",
            "Installing visdom script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tqdm==4.54.1\n",
            "Best match: tqdm 4.54.1\n",
            "Adding tqdm 4.54.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboardX==2.1\n",
            "Best match: tensorboardX 2.1\n",
            "Adding tensorboardX 2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opencv-python==4.4.0.46\n",
            "Best match: opencv-python 4.4.0.46\n",
            "Adding opencv-python 4.4.0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-image==0.17.2\n",
            "Best match: scikit-image 0.17.2\n",
            "Adding scikit-image 0.17.2 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.5.4\n",
            "Best match: scipy 1.5.4\n",
            "Adding scipy 1.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.19.4\n",
            "Best match: numpy 1.19.4\n",
            "Adding numpy 1.19.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchfile==0.1.0\n",
            "Best match: torchfile 0.1.0\n",
            "Adding torchfile 0.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for jsonpatch==1.28\n",
            "Best match: jsonpatch 1.28\n",
            "Adding jsonpatch 1.28 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tornado==5.1.1\n",
            "Best match: tornado 5.1.1\n",
            "Adding tornado 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyzmq==20.0.0\n",
            "Best match: pyzmq 20.0.0\n",
            "Adding pyzmq 20.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websocket-client==0.57.0\n",
            "Best match: websocket-client 0.57.0\n",
            "Adding websocket-client 0.57.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.12.4\n",
            "Best match: protobuf 3.12.4\n",
            "Adding protobuf 3.12.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for networkx==2.5\n",
            "Best match: networkx 2.5\n",
            "Adding networkx 2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for imageio==2.4.1\n",
            "Best match: imageio 2.4.1\n",
            "Adding imageio 2.4.1 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyWavelets==1.1.1\n",
            "Best match: PyWavelets 1.1.1\n",
            "Adding PyWavelets 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tifffile==2020.9.3\n",
            "Best match: tifffile 2020.9.3\n",
            "Adding tifffile 2020.9.3 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for jsonpointer==2.0\n",
            "Best match: jsonpointer 2.0\n",
            "Adding jsonpointer 2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2020.12.5\n",
            "Best match: certifi 2020.12.5\n",
            "Adding certifi 2020.12.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==50.3.2\n",
            "Best match: setuptools 50.3.2\n",
            "Adding setuptools 50.3.2 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for decorator==4.4.2\n",
            "Best match: decorator 4.4.2\n",
            "Adding decorator 4.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.7\n",
            "Best match: pyparsing 2.4.7\n",
            "Adding pyparsing 2.4.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.3.1\n",
            "Best match: kiwisolver 1.3.1\n",
            "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for iPERCore==0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1DYsa76zvMY"
      },
      "source": [
        "## 1.3 Download assets\n",
        "The assets contain all pre-trained models (**checkpoints.zip**), and other executable files (**executables.zip**, this one is only used for Windows. Linux ignores it), such as ffmpeg and ffprobe.\n",
        "\n",
        "Download links: \n",
        "  - checkpoints: https://download.impersonator.org/iper_plus_plus_latest_checkpoints.zip\n",
        "  - samples: https://download.impersonator.org/iper_plus_plus_latest_samples.zip\n",
        "\n",
        "You can manually download the **checkpoints.zip**, unzip it, and mv the **checkpoints** (as well as the **samples**) to **assets** folder. \n",
        "\n",
        " Otherwise, you can just run the following scripts to automaticially do these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFnPDBHN5WO",
        "outputId": "7388458e-be33-449b-9d0b-09114e93d693"
      },
      "source": [
        "# Download all checkpoints\n",
        "!wget -O assets/checkpoints.zip \"https://download.impersonator.org/iper_plus_plus_latest_checkpoints.zip\"\n",
        "!unzip -o assets/checkpoints.zip -d assets/\n",
        "\n",
        "!rm assets/checkpoints.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 09:38:31--  https://download.impersonator.org/iper_plus_plus_latest_checkpoints.zip\n",
            "Resolving download.impersonator.org (download.impersonator.org)... 101.32.75.151\n",
            "Connecting to download.impersonator.org (download.impersonator.org)|101.32.75.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: ./iper_plus_plus_1.0.0_checkpoints.zip [following]\n",
            "--2020-12-20 09:38:32--  https://download.impersonator.org/iper_plus_plus_1.0.0_checkpoints.zip\n",
            "Reusing existing connection to download.impersonator.org:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://1drv.ws/u/s!AjjUqiJZsj8whLkwQyrk3W9_H7MzNA?e=rRje0G [following]\n",
            "--2020-12-20 09:38:32--  https://1drv.ws/u/s!AjjUqiJZsj8whLkwQyrk3W9_H7MzNA?e=rRje0G\n",
            "Resolving 1drv.ws (1drv.ws)... 168.235.93.122\n",
            "Connecting to 1drv.ws (1drv.ws)|168.235.93.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: https://ciphww.dm.files.1drv.com/y4mgYHpttD4H4M9NLcMyFA9E5BCWHXfqajpuUlLOERnY7cHnoojmlXHZUC50chZPVdBXGKaF4wz3qf9L8kpXEApBeiqhAFEM1B-w4Mblqfn3-7FK1Fg78CF8uNitVy_DfYtrEyUySK6pveABKzoXtlRD9DJ3KNw83HO3_AqgtHMPMdmjy7mVJIR6ndrSNdzLNRWchpKCqsmtEdDdz9PXn7BEQ/checkpoints.zip?download&psid=1 [following]\n",
            "--2020-12-20 09:38:33--  https://ciphww.dm.files.1drv.com/y4mgYHpttD4H4M9NLcMyFA9E5BCWHXfqajpuUlLOERnY7cHnoojmlXHZUC50chZPVdBXGKaF4wz3qf9L8kpXEApBeiqhAFEM1B-w4Mblqfn3-7FK1Fg78CF8uNitVy_DfYtrEyUySK6pveABKzoXtlRD9DJ3KNw83HO3_AqgtHMPMdmjy7mVJIR6ndrSNdzLNRWchpKCqsmtEdDdz9PXn7BEQ/checkpoints.zip?download&psid=1\n",
            "Resolving ciphww.dm.files.1drv.com (ciphww.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to ciphww.dm.files.1drv.com (ciphww.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243286164 (1.2G) [application/zip]\n",
            "Saving to: ‘assets/checkpoints.zip’\n",
            "\n",
            "assets/checkpoints. 100%[===================>]   1.16G  44.5MB/s    in 31s     \n",
            "\n",
            "2020-12-20 09:39:05 (37.7 MB/s) - ‘assets/checkpoints.zip’ saved [1243286164/1243286164]\n",
            "\n",
            "Archive:  assets/checkpoints.zip\n",
            "   creating: assets/checkpoints/\n",
            "   creating: assets/checkpoints/detection/\n",
            "  inflating: assets/checkpoints/detection/point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth  \n",
            "   creating: assets/checkpoints/inpainting/\n",
            "  inflating: assets/checkpoints/inpainting/deepfillv2_256x256_8x2_places_20200619-10d15793.pth  \n",
            "   creating: assets/checkpoints/losses/\n",
            "  inflating: assets/checkpoints/losses/sphere20a_20171020.pth  \n",
            "  inflating: assets/checkpoints/losses/vgg19-dcbb9e9d.pth  \n",
            "   creating: assets/checkpoints/mattors/\n",
            "  inflating: assets/checkpoints/mattors/exp-schp-lip.pth  \n",
            "  inflating: assets/checkpoints/mattors/gca_r34_4x10_200k_comp1k_SAD-34.77_20200604_213848-4369bea0.pth  \n",
            "   creating: assets/checkpoints/neural_renders/\n",
            "  inflating: assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth  \n",
            "   creating: assets/checkpoints/pose2d/\n",
            "  inflating: assets/checkpoints/pose2d/mobilenet_body18.pth  \n",
            "  inflating: assets/checkpoints/pose2d/openpose_body25.pth  \n",
            "   creating: assets/checkpoints/pose3d/\n",
            "  inflating: assets/checkpoints/pose3d/front_body.json  \n",
            "  inflating: assets/checkpoints/pose3d/front_facial.json  \n",
            "  inflating: assets/checkpoints/pose3d/gmm_08.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/head.json  \n",
            "  inflating: assets/checkpoints/pose3d/mapper_fim_enc.txt  \n",
            "  inflating: assets/checkpoints/pose3d/mapper_uv.txt  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_faces.npy  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_model.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_model_with_hand_v2.pkl  \n",
            "  inflating: assets/checkpoints/pose3d/smpl_part_info.json  \n",
            "  inflating: assets/checkpoints/pose3d/spin_ckpt.pth  \n",
            "   creating: assets/checkpoints/restorers/\n",
            "  inflating: assets/checkpoints/restorers/esrgan_psnr_x4c64b23g32_1x16_1000k_div2k_20200420-bf5c993c.pth  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_QjX1FzsEQI",
        "outputId": "eabd30fe-6717-4174-9a4c-9676bf40e018"
      },
      "source": [
        "# download samples\n",
        "!wget -O assets/samples.zip  \"https://download.impersonator.org/iper_plus_plus_latest_samples.zip\"\n",
        "!unzip -o assets/samples.zip -d  assets\n",
        "!rm assets/samples.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-20 09:39:41--  https://download.impersonator.org/iper_plus_plus_latest_samples.zip\n",
            "Resolving download.impersonator.org (download.impersonator.org)... 101.32.75.151\n",
            "Connecting to download.impersonator.org (download.impersonator.org)|101.32.75.151|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: ./iper_plus_plus_1.0.0_samples.zip [following]\n",
            "--2020-12-20 09:39:41--  https://download.impersonator.org/iper_plus_plus_1.0.0_samples.zip\n",
            "Reusing existing connection to download.impersonator.org:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://1drv.ws/u/s!AjjUqiJZsj8whLobQPpoxo2hfhURrA?e=EUyIC2 [following]\n",
            "--2020-12-20 09:39:42--  https://1drv.ws/u/s!AjjUqiJZsj8whLobQPpoxo2hfhURrA?e=EUyIC2\n",
            "Resolving 1drv.ws (1drv.ws)... 168.235.93.122\n",
            "Connecting to 1drv.ws (1drv.ws)|168.235.93.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: https://cirftg.dm.files.1drv.com/y4m3dRmiJGUnRi7aoD7SSR0c30Onmy6otoj9iXLx-OWlQtupTRWUReYBRIbEruzowkaYFyFZjrqmdpIAHJbdvk5hsAZgLdrUjgbY5jbDYuZmi6w7b1-RYcpjbARuPtM9GUpqv4woZpQxtEm4Np3xR79gJKNPE_OuyBqs5m1mxA9d8p6Hy6t3p0ESeEyZmp10cNqNK_cRMmG1nVSTscYyOOD7w/samples.zip?download&psid=1 [following]\n",
            "--2020-12-20 09:39:42--  https://cirftg.dm.files.1drv.com/y4m3dRmiJGUnRi7aoD7SSR0c30Onmy6otoj9iXLx-OWlQtupTRWUReYBRIbEruzowkaYFyFZjrqmdpIAHJbdvk5hsAZgLdrUjgbY5jbDYuZmi6w7b1-RYcpjbARuPtM9GUpqv4woZpQxtEm4Np3xR79gJKNPE_OuyBqs5m1mxA9d8p6Hy6t3p0ESeEyZmp10cNqNK_cRMmG1nVSTscYyOOD7w/samples.zip?download&psid=1\n",
            "Resolving cirftg.dm.files.1drv.com (cirftg.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to cirftg.dm.files.1drv.com (cirftg.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251759768 (240M) [application/zip]\n",
            "Saving to: ‘assets/samples.zip’\n",
            "\n",
            "assets/samples.zip  100%[===================>] 240.10M  22.7MB/s    in 15s     \n",
            "\n",
            "2020-12-20 09:39:57 (16.5 MB/s) - ‘assets/samples.zip’ saved [251759768/251759768]\n",
            "\n",
            "Archive:  assets/samples.zip\n",
            "  inflating: assets/samples/references/aini.mp4  \n",
            "  inflating: assets/samples/references/akGexYZug2Q_2.mp4.mp4  \n",
            "  inflating: assets/samples/references/akun_1.mp4  \n",
            "  inflating: assets/samples/references/akun_2.mp4  \n",
            "  inflating: assets/samples/references/Av37667655_2.mp4  \n",
            "  inflating: assets/samples/references/bantangzhuyi_1.mp4  \n",
            "  inflating: assets/samples/references/BV1rD4y1Q72j_2.mp4  \n",
            "  inflating: assets/samples/references/chengfengpolang_1.mp4  \n",
            "  inflating: assets/samples/references/kuailechongbai_boy.mp4  \n",
            "  inflating: assets/samples/references/mabaoguo.mp4  \n",
            "  inflating: assets/samples/references/mabaoguo_short.mp4  \n",
            "   creating: assets/samples/sources/001_18_1/\n",
            "  inflating: assets/samples/sources/001_18_1/000.jpg  \n",
            "  inflating: assets/samples/sources/001_18_1/190.jpg  \n",
            "   creating: assets/samples/sources/001_19_1/\n",
            "  inflating: assets/samples/sources/001_19_1/000.jpg  \n",
            "  inflating: assets/samples/sources/001_19_1/120.jpg  \n",
            "   creating: assets/samples/sources/5NJIkUmh_h0/\n",
            " extracting: assets/samples/sources/5NJIkUmh_h0/0001.PNG  \n",
            "   creating: assets/samples/sources/91iZ9x8NI0S/\n",
            "  inflating: assets/samples/sources/91iZ9x8NI0S/frame_00000026.png  \n",
            "   creating: assets/samples/sources/afan_3/\n",
            "   creating: assets/samples/sources/afan_3/afan_3/\n",
            "  inflating: assets/samples/sources/afan_3/afan_3/IMG_7129.JPG  \n",
            "  inflating: assets/samples/sources/afan_3/afan_3/IMG_7131.JPG  \n",
            "  inflating: assets/samples/sources/afan_3/IMG_7128.JPG  \n",
            "   creating: assets/samples/sources/afan_6/\n",
            "   creating: assets/samples/sources/afan_6/afan_6/\n",
            "   creating: assets/samples/sources/afan_6/afan_6=ns=2/\n",
            "  inflating: assets/samples/sources/afan_6/afan_6=ns=2/IMG_7218.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6=ns=2/IMG_7221.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7218.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7219.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7220.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7221.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7222.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7223.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/afan_6/IMG_7224.JPG  \n",
            "  inflating: assets/samples/sources/afan_6/IMG_7217.JPG  \n",
            "   creating: assets/samples/sources/axing_1/\n",
            "  inflating: assets/samples/sources/axing_1/000.jpg  \n",
            "  inflating: assets/samples/sources/axing_1/125.jpg  \n",
            "   creating: assets/samples/sources/axing_7/\n",
            "   creating: assets/samples/sources/axing_7/axing_7/\n",
            "   creating: assets/samples/sources/axing_7/axing_7=2/\n",
            "  inflating: assets/samples/sources/axing_7/axing_7=2/IMG_7234.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7=2/IMG_7237.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7234.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7235.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7236.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7237.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7238.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/axing_7/IMG_7239.JPG  \n",
            "  inflating: assets/samples/sources/axing_7/IMG_7233.JPG  \n",
            "   creating: assets/samples/sources/caixukun2/\n",
            "  inflating: assets/samples/sources/caixukun2/caixukun_front_full_size.png  \n",
            "  inflating: assets/samples/sources/caixukun2/frame00000597.png  \n",
            "   creating: assets/samples/sources/cartoon_12/\n",
            "  inflating: assets/samples/sources/cartoon_12/0.jpg  \n",
            "  inflating: assets/samples/sources/cartoon_12/1.jpg  \n",
            " extracting: assets/samples/sources/donald_trump_2/00000.PNG  \n",
            "   creating: assets/samples/sources/fange_1/\n",
            "   creating: assets/samples/sources/fange_1/fange_1_ns=2/\n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=2/IMG_7227.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=2/IMG_7230.JPG  \n",
            "   creating: assets/samples/sources/fange_1/fange_1_ns=6/\n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7227.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7228.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7229.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7230.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7231.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/fange_1_ns=6/IMG_7232.JPG  \n",
            "  inflating: assets/samples/sources/fange_1/IMG_7225.JPG  \n",
            "   creating: assets/samples/sources/google_1/\n",
            "  inflating: assets/samples/sources/google_1/0.jpg  \n",
            "   creating: assets/samples/sources/google_2/\n",
            "  inflating: assets/samples/sources/google_2/01.jpg  \n",
            "  inflating: assets/samples/sources/google_2/02.png  \n",
            "   creating: assets/samples/sources/mabaoguo_v2/\n",
            "  inflating: assets/samples/sources/mabaoguo_v2/mabaoguo_1.png  \n",
            "  inflating: assets/samples/sources/mabaoguo_v2/mabaoguo_back_full_size.png  \n",
            "  inflating: assets/samples/sources/skirts3.jpg  \n",
            "   creating: assets/samples/sources/stephen_curry/\n",
            "  inflating: assets/samples/sources/stephen_curry/0000.webp  \n",
            "   creating: assets/samples/sources/WabSbZp9dII_1/\n",
            " extracting: assets/samples/sources/WabSbZp9dII_1/frame_00011159.png  \n",
            " extracting: assets/samples/sources/wangyibo_2.jpg  \n",
            "   creating: assets/samples/sources/wtW2R7hTImA_1/\n",
            "  inflating: assets/samples/sources/wtW2R7hTImA_1/frame_00000920.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffbq0leDOUGS"
      },
      "source": [
        "# 2 Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9KymQM8z6sH",
        "outputId": "0fc928b6-1aac-4a8d-c046-d26906df317a"
      },
      "source": [
        "cd /content/iPERCore/"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/iPERCore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJskZDTiEKMB"
      },
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import platform\n",
        "import argparse\n",
        "import time\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import cv2\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_PATH = '/content/20161108_112909.jpg'\n",
        "VIDEO_PATH = '/content/mirte_dance.mp4'\n",
        "MODEL_NAME = 'jeroen_mirte'\n",
        "VIDEO_CROPPED_PATH = VIDEO_PATH.replace('.mp4','_cropped.mp4')"
      ]
    },
    {
      "source": [
        "## 2.1 Crop video\n",
        "The dance-video of my GF was from a duo dance, so I needed to crop the video."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open the video\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "w_frame, h_frame = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps, frames = cap.get(cv2.CAP_PROP_FPS), cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "print(f\"frame width: {w_frame}, height: {h_frame}, fps: {fps}\")\n",
        "\n",
        "# Cropping values\n",
        "x,y,h,w = 0,0,200,w_frame\n",
        "\n",
        "# output\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter(VIDEO_CROPPED_PATH, fourcc, fps, (w, h))\n",
        "\n",
        "cnt = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    cnt += 1\n",
        "    if ret:\n",
        "        # Croping image\n",
        "        crop_frame = frame[y:y+h, x:x+w]\n",
        "\n",
        "        # stop at frame X   \n",
        "        if 350 < cnt :\n",
        "            out.write(crop_frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo9IgZwsOmBd"
      },
      "source": [
        "## 2.2 Details of Config\n",
        " - gpu_ids (str): the gpu_ids, default is \"0\";\n",
        " - image_size (int): the image size, default is 512;\n",
        " - num_source (int): the number of source images for Attention, default is 2. Large needs more GPU memory;\n",
        " - assets_dir (str): the assets directory. This is very important, and there are the configurations and all pre-trained checkpoints;\n",
        " - output_dir (str): the output directory;\n",
        "\n",
        " - src_path (str): the source input information. \n",
        "       All source paths and it supports multiple paths, uses \"|\" as the separator between all paths. \n",
        "       The format is \"src_path_1|src_path_2|src_path_3\". \n",
        "       \n",
        "       Each src_input is \"path?=path1,name?=name1,bg_path?=bg_path1\". \n",
        "       \n",
        "       It must contain 'path'. If 'name' and 'bg_path' are empty, they will be ignored.\n",
        "\n",
        "       The 'path' could be an image path, a path of a directory contains source images, and a video path.\n",
        "\n",
        "       The 'name' is the rename of this source input, if it is empty, we will ignore it, and use the filename of the path.\n",
        "\n",
        "       The 'bg_path' is the actual background path if provided, otherwise we will ignore it.\n",
        "       \n",
        "       There are several examples of formated source paths,\n",
        "\n",
        "        1. \"path?=path1,name?=name1,bg_path?=bg_path1|path?=path2,name?=name2,bg_path?=bg_path2\",\n",
        "        this input will be parsed as [{path: path1, name: name1, bg_path:bg_path1},\n",
        "        {path: path2, name: name2, bg_path: bg_path2}];\n",
        "\n",
        "        2. \"path?=path1,name?=name1|path?=path2,name?=name2\", this input will be parsed as\n",
        "        [{path: path1, name:name1}, {path: path2, name: name2}];\n",
        "\n",
        "        3. \"path?=path1\", this input will be parsed as [{path: path1}].\n",
        "\n",
        "        4. \"path1\", this will be parsed as [{path: path1}].\n",
        "\n",
        " - ref_path (str): the reference input information.\n",
        "       \n",
        "       All reference paths. It supports multiple paths, and uses \"|\" as the separator between all paths.\n",
        "       The format is \"ref_path_1|ref_path_2|ref_path_3\".\n",
        "\n",
        "       Each ref_path is \"path?=path1,name?=name1,audio?=audio_path1,fps?=30,pose_fc?=300,cam_fc?=150\".\n",
        "\n",
        "       It must contain 'path', and others could be empty, and they will be ignored.\n",
        "\n",
        "       The 'path' could be an image path, a path of a directory contains images of a same person, and a video path.\n",
        "\n",
        "       The 'name' is the rename of this source input, if it is empty, we will ignore it, and use the filename of the path.\n",
        "\n",
        "       The 'audio' is the audio path, if it is empty, we will ignore it. If the 'path' is a video,\n",
        "        you can ignore this, and we will firstly extract the audio information of this video (if it has audio channel).\n",
        "\n",
        "       The 'fps' is fps of the final outputs, if it is empty, we will set it as the default fps 25.\n",
        "\n",
        "       The 'pose_fc' is the smooth factor of the temporal poses. The smaller of this value, the smoother of the temporal poses. If it is empty, we will set it as the default 300. In the most cases, using the default 300 is enough, and if you find the poses of the outputs are not stable, you can decrease this value. Otherwise, if you find the poses of the outputs are over stable, you can increase this value.\n",
        "\n",
        "       The 'cam_fc' is the smooth factor of the temporal cameras (locations in the image space). The smaller of this value, the smoother of the locations in sequences. If it is empty, we will set it as the default 150. In the most cases, the default 150 is enough.\n",
        "\n",
        "       There are several examples of formated reference paths,\n",
        "\n",
        "        1. \"path?=path1,name?=name1,audio?=audio_path1,fps?=30,pose_fc?=300,cam_fc?=150|\n",
        "            path?=path2,name?=name2,audio?=audio_path2,fps?=25,pose_fc?=450,cam_fc?=200\",\n",
        "            this input will be parsed as\n",
        "            [{path: path1, name: name1, audio: audio_path1, fps: 30, pose_fc: 300, cam_fc: 150},\n",
        "             {path: path2, name: name2, audio: audio_path2, fps: 25, pose_fc: 450, cam_fc: 200}]\n",
        "\n",
        "        2. \"path?=path1,name?=name1, pose_fc?=450|path?=path2,name?=name2\", this input will be parsed as\n",
        "        [{path: path1, name: name1, fps: 25, pose_fc: 450, cam_fc: 150},\n",
        "         {path: path2, name: name2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        3. \"path?=path1|path?=path2\", this input will be parsed as\n",
        "        [{path: path1, fps:25, pose_fc: 300, cam_fc: 150}, {path: path2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        4. \"path1|path2\", this input will be parsed as\n",
        "        [{path: path1, fps:25, pose_fc: 300, cam_fc: 150}, {path: path2, fps: 25, pose_fc: 300, cam_fc: 150}].\n",
        "\n",
        "        5. \"path1\", this will be parsed as [{path: path1, fps: 25, pose_fc: 300, cam_fc: 150}]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vme5bj8xmfsC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNWVyAaeOhHP"
      },
      "source": [
        "# the gpu ids\n",
        "gpu_ids = \"0\"\n",
        "\n",
        "# the image size\n",
        "image_size = 512\n",
        "\n",
        "# the default number of source images, it will be updated if the actual number of sources <= num_source\n",
        "num_source = 1\n",
        "\n",
        "# the assets directory. This is very important, please download it from `one_drive_url` firstly.\n",
        "assets_dir = \"/content/iPERCore/assets\"\n",
        "\n",
        "# the output directory.\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# symlink from the actual assets directory to this current directory\n",
        "work_asserts_dir = os.path.join(\"./assets\")\n",
        "if not os.path.exists(work_asserts_dir):\n",
        "    os.symlink(osp.abspath(assets_dir), osp.abspath(work_asserts_dir),\n",
        "               target_is_directory=(platform.system() == \"Windows\"))\n",
        "\n",
        "cfg_path = osp.join(work_asserts_dir, \"configs\", \"deploy.toml\")\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "source": [
        "## 2.3 Run Scripts"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETaQCD0t1qqO",
        "outputId": "d5483de2-1351-4cbe-dbae-fe5881fa7e5f"
      },
      "source": [
        "model_id = MODEL_NAME + str(time.time())\n",
        "\n",
        "src_path = f\"\\\"path?={IMAGE_PATH},name?={model_id}_src\\\"\"\n",
        "\n",
        "ref_path = f\"\\\"path?={VIDEO_CROPPED_PATH},\" \\\n",
        "              f\"name?={model_id}_ref,\" \\\n",
        "              \"fps?=24,\" \\\n",
        "              \"pose_fc?=400\\\"\"\n",
        "print(ref_path)\n",
        "\n",
        "!python -m iPERCore.services.run_imitator  \\\n",
        "  --gpu_ids     $gpu_ids       \\\n",
        "  --num_source  $num_source    \\\n",
        "  --image_size  $image_size    \\\n",
        "  --output_dir  $output_dir    \\\n",
        "  --model_id    $model_id      \\\n",
        "  --cfg_path    $cfg_path      \\\n",
        "  --src_path    $src_path      \\\n",
        "  --ref_path    $ref_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"path?=/content/mufasa_crop.mp4,name?=jeroen_mufasa_1608467657.6595387_ref,fps?=24,pose_fc?=400\"\n",
            "ffmpeg -y -i /content/mufasa_crop.mp4 -ab 160k -ac 2 -ar 44100 -vn ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/audio.mp3 -loglevel quiet\n",
            "ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=r_frame_rate /content/mufasa_crop.mp4\n",
            "\tPre-processing: start...\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/20161108_112909.jpg\n",
            "\tbg_path: \n",
            "\tname: jeroen_mufasa_1608467657.6595387_src\n",
            "primitives_dir: ./results/primitives/jeroen_mufasa_1608467657.6595387_src\n",
            "processed_dir: ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed\n",
            "vid_info_path: ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "----------------------MetaProcess----------------------\n",
            "meta_input:\n",
            "\tpath: /content/mufasa_crop.mp4\n",
            "\tbg_path: \n",
            "\tname: jeroen_mufasa_1608467657.6595387_ref\n",
            "\taudio: ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/audio.mp3\n",
            "\tfps: 23.976\n",
            "\tpose_fc: 400.0\n",
            "\tcam_fc: 100\n",
            "primitives_dir: ./results/primitives/jeroen_mufasa_1608467657.6595387_ref\n",
            "processed_dir: ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed\n",
            "vid_info_path: ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/vid_info.pkl\n",
            "-------------------------------------------------------\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/orig_images...\n",
            "100% 1/1 [00:00<00:00,  5.25it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/orig_images by estimated boxes ...\n",
            "1it [00:00, 28.18it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/images ...\n",
            "100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "\t1.4 Preprocessing, running Preprocessor to find 25 candidates front images in ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/images ...\n",
            "100% 1/1 [00:00<00:00, 31.40it/s]\n",
            "\t1.4 Preprocessing, finish find the front images ....\n",
            "\t1.5 Preprocessing, running Preprocessor to run human matting in ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/parse ... \n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "100% 1/1 [00:00<00:00,  3.77it/s]\n",
            "\t1.5 Preprocessing, finish run human matting.\n",
            "\t1.6 Preprocessing, running Preprocessor to run background inpainting ...\n",
            "100% 1/1 [00:00<00:00,  1.51it/s]\n",
            "\t1.6 Preprocessing, finish run background inpainting ....\n",
            "\t1.7 Preprocessing, saving visualization to ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/visual.mp4 ...\n",
            "100% 1/1 [00:00<00:00,  1.77it/s]\n",
            "ffmpeg -y -i ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/visual.mp4.avi -vcodec h264 ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/visual.mp4 -loglevel quiet\n",
            "\t1.7 Preprocessing, saving visualization to ./results/primitives/jeroen_mufasa_1608467657.6595387_src/processed/visual.mp4 ...\n",
            "Preprocessor has finished...\n",
            "/content/mufasa_crop.mp4 Writing frames to file\n",
            "ffmpeg -i /content/mufasa_crop.mp4 -start_number 0 ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/orig_images/frame_%08d.png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/mufasa_crop.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.61.100\n",
            "  Duration: 00:00:45.46, start: 0.000000, bitrate: 1243 kb/s\n",
            "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 210x360 [SAR 1:1 DAR 7:12], 1242 kb/s, 23.98 fps, 23.98 tbr, 23976 tbn, 2997 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to './results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/orig_images/frame_%08d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 210x360 [SAR 1:1 DAR 7:12], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn, 23.98 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1090 fps=171 q=-0.0 Lsize=N/A time=00:00:45.46 bitrate=N/A speed=7.14x    \n",
            "video:148955kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "\t1.1 Preprocessing, running Preprocessor to detect the human boxes of ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/orig_images...\n",
            "100% 1090/1090 [01:14<00:00, 14.67it/s]\n",
            "\t1.1 Preprocessing, finish detect the human boxes of ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/orig_images ...\n",
            "\t1.2 Preprocessing, cropping all images in ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/orig_images by estimated boxes ...\n",
            "1090it [00:10, 103.09it/s]\n",
            "\t1.2 Preprocessing, finish crop the human by boxes, and save them in ./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/images ...\n",
            "\t1.3 Preprocessing, running Preprocessor to 3D pose estimation of all images in./results/primitives/jeroen_mufasa_1608467657.6595387_ref/processed/images ...\n",
            "100% 35/35 [00:22<00:00,  1.57it/s]\n",
            "\t1.3 Preprocessing, finish 3D pose estimation successfully ....\n",
            "Preprocessor has finished...\n",
            "\t\tPre-processing: digital deformation start...\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "\t\tPre-processing: digital deformation completed...\n",
            "the current number of sources are 1, while the pre-defined number of sources are 1. \n",
            "\tPre-processing: successfully...\n",
            "Step 2: running personalization on\n",
            "#train video clips = 1\n",
            "  0% 0/100 [00:00<?, ?it/s]Network AttLWB-SPADE was created\n",
            "Network patch_global was created\n",
            "Loading vgg19 from ./assets/checkpoints/losses/vgg19-dcbb9e9d.pth...\n",
            "Loading face model from ./assets/checkpoints/losses/sphere20a_20171020.pth\n",
            "Loading net: ./assets/checkpoints/neural_renders/AttLWB-SPADE_id_G_2020-05-18.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "100% 100/100 [02:14<00:00,  1.34s/it]\n",
            "saving the personalized model in ./results/models/jeroen_mufasa_1608467657.6595387/personalized.pth\n",
            "Step 2: personalization done, saved in ./results/models/jeroen_mufasa_1608467657.6595387/personalized.pth...\n",
            "Step 3: running imitator.\n",
            "Network AttLWB-SPADE was created\n",
            "Loading net from ./results/models/jeroen_mufasa_1608467657.6595387/personalized.pth\n",
            "Model Imitator was created\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            " 19% 203/1090 [00:30<02:12,  6.69it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJg2YdjYiulk"
      },
      "source": []
    }
  ]
}